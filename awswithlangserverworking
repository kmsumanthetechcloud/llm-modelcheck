import streamlit as st
import requests
from bs4 import BeautifulSoup
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_ollama import OllamaLLM
import difflib
import os
from dotenv import load_dotenv

# ✅ Load environment variables
load_dotenv()
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")

# ✅ Fixed website URL
FIXED_URL = "http://13.233.236.167/"

# ✅ Fetch and clean website content
@st.cache_data(show_spinner=True)
def fetch_website_text(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        text = soup.get_text(separator=". ").strip()
        return text
    except Exception as e:
        return f"Error fetching website content: {e}"

# ✅ Context extraction logic
def find_relevant_text(text, query, window=5):
    sentences = text.split(". ")
    query_words = set(query.lower().split())
    relevant_sentences = []

    for idx, sentence in enumerate(sentences):
        if any(word in sentence.lower() for word in query_words):
            relevant_sentences.append(sentence)
            relevant_sentences.extend(sentences[idx+1:idx+3])  # Add context
            break

    if not relevant_sentences:
        matches = difflib.get_close_matches(query, sentences, n=1, cutoff=0.4)
        if matches:
            idx = sentences.index(matches[0])
            relevant_sentences.append(matches[0])
            relevant_sentences.extend(sentences[idx+1:idx+3])

    return ". ".join(relevant_sentences) if relevant_sentences else ""

# ✅ Streamlit UI
st.title("Langchain Demo With llama2 API - Website QA with Smart Context")

website_content = fetch_website_text(FIXED_URL)

if website_content.startswith("Error"):
    st.error(website_content)
else:
    st.success("Website content fetched successfully.")

input_text = st.text_input("Search the topic you want")

if input_text and not website_content.startswith("Error"):
    context = find_relevant_text(website_content, input_text)

    if not context:
        st.warning("Sorry, the website content does not contain information related to your question.")
    else:
        # Prompt with context
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful assistant. Use ONLY the provided CONTEXT to answer briefly."),
            ("user", "CONTEXT: {context}\nQUESTION: {question}")
        ])

        llm = OllamaLLM(model="gemma3:1b")
        output_parser = StrOutputParser()
        chain = prompt | llm | output_parser

        response = chain.invoke({"context": context, "question": input_text})
        st.write("Answer:")
        st.write(response)
